2022-12-08 20:13:03.696217: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-08 20:13:05.930863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-08 20:13:05.959094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-08 20:13:05.959490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-08 20:13:05.978925: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-08 20:13:05.979665: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-08 20:13:05.980062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-08 20:13:05.980394: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-08 20:13:06.863382: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-08 20:13:06.863752: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-08 20:13:06.864089: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-08 20:13:06.864333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 18203 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6
WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2022-12-08 20:13:07.797225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-08 20:13:07.797569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-08 20:13:07.797821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-08 20:13:07.798127: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-08 20:13:07.798386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-08 20:13:07.798574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 18203 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6
2022-12-08 20:13:07.846023: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled
Epoch 1/10
2022-12-08 20:13:09.321059: W tensorflow/c/c_api.cc:349] Operation '{name:'lstm/while' id:199 op device:{requested: '', assigned: ''} def:{{{node lstm/while}} = While[T=[DT_INT32, DT_INT32, DT_INT32, DT_VARIANT, DT_FLOAT, 12032779882972063251, DT_VARIANT, DT_VARIANT, DT_VARIANT, DT_VARIANT, DT_VARIANT], _lower_using_switch_merge=true, _num_original_outputs=44, _read_only_resource_inputs=[8, 9, 10], _stateful_parallelism=false, body=lstm_while_body_101[], cond=lstm_while_cond_100[], output_shapes=[[], [], [], [], [?,96], 17584562593488234240, [], [], [], [], []], parallel_iterations=32](lstm/while/loop_counter, lstm/while/maximum_iterations, lstm/time, lstm/TensorArrayV2_1, lstm/zeros, lstm/zeros_1, lstm/strided_slice_1, lstm/TensorArrayUnstack/TensorListFromTensor, lstm/lstm_cell/kernel, lstm/lstm_cell/recurrent_kernel, lstm/lstm_cell/bias, lstm/while/EmptyTensorList, lstm/while/EmptyTensorList_1, lstm/while/EmptyTensorList_2, lstm/while/EmptyTensorList_3, lstm/while/EmptyTensorList_4, lstm/while/EmptyTensorList_5, lstm/while/EmptyTensorList_6, lstm/while/EmptyTensorList_7, lstm/while/EmptyTensorList_8, lstm/while/EmptyTensorList_9, lstm/while/EmptyTensorList_10, lstm/while/EmptyTensorList_11, lstm/while/EmptyTensorList_12, lstm/while/EmptyTensorList_13, lstm/while/EmptyTensorList_14, lstm/while/EmptyTensorList_15, lstm/while/EmptyTensorList_16, lstm/while/EmptyTensorList_17, lstm/while/EmptyTensorList_18, lstm/while/EmptyTensorList_19, lstm/while/EmptyTensorList_20, lstm/while/EmptyTensorList_21, lstm/while/EmptyTensorList_22, lstm/while/EmptyTensorList_23, lstm/while/EmptyTensorList_24, lstm/while/EmptyTensorList_25, lstm/while/EmptyTensorList_26, lstm/while/EmptyTensorList_27, lstm/while/EmptyTensorList_28, lstm/while/EmptyTensorList_29, lstm/while/EmptyTensorList_30, lstm/while/EmptyTensorList_31, lstm/while/EmptyTensorList_32)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.
2022-12-08 20:13:12.257842: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
/home/ubuntu/anaconda3/envs/cs-230-project/lib/python3.9/site-packages/keras/engine/training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.
  updates = self.state_updates
3300/3300 - 463s - loss: 0.2257 - mean_squared_error: 0.0154 - root_mean_squared_error: 0.1242 - val_loss: 0.1916 - val_mean_squared_error: 0.0084 - val_root_mean_squared_error: 0.0918 - 463s/epoch - 140ms/step
Epoch 2/10
3300/3300 - 469s - loss: 0.2116 - mean_squared_error: 0.0079 - root_mean_squared_error: 0.0890 - val_loss: 0.2139 - val_mean_squared_error: 0.0074 - val_root_mean_squared_error: 0.0862 - 469s/epoch - 142ms/step
Epoch 3/10
3300/3300 - 467s - loss: 0.2051 - mean_squared_error: 0.0068 - root_mean_squared_error: 0.0825 - val_loss: 0.2070 - val_mean_squared_error: 0.0066 - val_root_mean_squared_error: 0.0811 - 467s/epoch - 141ms/step
Epoch 4/10
3300/3300 - 466s - loss: 0.1897 - mean_squared_error: 0.0074 - root_mean_squared_error: 0.0862 - val_loss: 0.1758 - val_mean_squared_error: 0.0095 - val_root_mean_squared_error: 0.0976 - 466s/epoch - 141ms/step
Epoch 5/10
3300/3300 - 476s - loss: 0.1705 - mean_squared_error: 0.0123 - root_mean_squared_error: 0.1111 - val_loss: 0.1658 - val_mean_squared_error: 0.0143 - val_root_mean_squared_error: 0.1197 - 476s/epoch - 144ms/step
Epoch 6/10
3300/3300 - 467s - loss: 0.1536 - mean_squared_error: 0.0148 - root_mean_squared_error: 0.1217 - val_loss: 0.1468 - val_mean_squared_error: 0.0157 - val_root_mean_squared_error: 0.1252 - 467s/epoch - 141ms/step
Epoch 7/10
3300/3300 - 463s - loss: 0.1451 - mean_squared_error: 0.0167 - root_mean_squared_error: 0.1293 - val_loss: 0.1399 - val_mean_squared_error: 0.0174 - val_root_mean_squared_error: 0.1320 - 463s/epoch - 140ms/step
Epoch 8/10
3300/3300 - 465s - loss: 0.1388 - mean_squared_error: 0.0185 - root_mean_squared_error: 0.1358 - val_loss: 0.1398 - val_mean_squared_error: 0.0199 - val_root_mean_squared_error: 0.1410 - 465s/epoch - 141ms/step
Epoch 9/10
3300/3300 - 448s - loss: 0.1349 - mean_squared_error: 0.0199 - root_mean_squared_error: 0.1410 - val_loss: 0.1320 - val_mean_squared_error: 0.0205 - val_root_mean_squared_error: 0.1431 - 448s/epoch - 136ms/step
Epoch 10/10
3300/3300 - 231s - loss: 0.1280 - mean_squared_error: 0.0202 - root_mean_squared_error: 0.1421 - val_loss: 0.1269 - val_mean_squared_error: 0.0210 - val_root_mean_squared_error: 0.1450 - 231s/epoch - 70ms/step
Traceback (most recent call last):
  File "/home/ubuntu/cs230-project/trainLSTM.py", line 303, in <module>
    plotLossOverEpochs(history.history,'training_'+loss_f+'_'+str(nHLayers)+'_'+str(nHUnits)+'_'+str(learning_r))
  File "/home/ubuntu/cs230-project/utilities.py", line 73, in plotLossOverEpochs
    plt.savefig(fig_name)
  File "/home/ubuntu/anaconda3/envs/cs-230-project/lib/python3.9/site-packages/matplotlib/pyplot.py", line 954, in savefig
    res = fig.savefig(*args, **kwargs)
  File "/home/ubuntu/anaconda3/envs/cs-230-project/lib/python3.9/site-packages/matplotlib/figure.py", line 3274, in savefig
    self.canvas.print_figure(fname, **kwargs)
  File "/home/ubuntu/anaconda3/envs/cs-230-project/lib/python3.9/site-packages/matplotlib/backend_bases.py", line 2285, in print_figure
    with cbook._setattr_cm(self, manager=None), \
  File "/home/ubuntu/anaconda3/envs/cs-230-project/lib/python3.9/contextlib.py", line 119, in __enter__
    return next(self.gen)
  File "/home/ubuntu/anaconda3/envs/cs-230-project/lib/python3.9/site-packages/matplotlib/backend_bases.py", line 2192, in _switch_canvas_and_return_print_method
    raise ValueError(
ValueError: Format '0300903724851807e-05' is not supported (supported formats: eps, jpeg, jpg, pdf, pgf, png, ps, raw, rgba, svg, svgz, tif, tiff, webp)
