2022-12-08 20:13:34.905355: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-08 20:13:37.818823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-08 20:13:37.874446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-08 20:13:37.874838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-08 20:13:37.893756: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-08 20:13:37.894478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-08 20:13:37.894873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-08 20:13:37.895170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-08 20:13:39.052534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-08 20:13:39.053009: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-08 20:13:39.053346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-08 20:13:39.053591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 17350 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6
WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
2022-12-08 20:13:40.265864: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-08 20:13:40.266245: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-08 20:13:40.266499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-08 20:13:40.266827: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-08 20:13:40.267096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-08 20:13:40.267295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 17350 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6
2022-12-08 20:13:40.331570: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled
Epoch 1/10
2022-12-08 20:13:41.915495: W tensorflow/c/c_api.cc:349] Operation '{name:'lstm/while' id:199 op device:{requested: '', assigned: ''} def:{{{node lstm/while}} = While[T=[DT_INT32, DT_INT32, DT_INT32, DT_VARIANT, DT_FLOAT, 12032779882972063251, DT_VARIANT, DT_VARIANT, DT_VARIANT, DT_VARIANT, DT_VARIANT], _lower_using_switch_merge=true, _num_original_outputs=44, _read_only_resource_inputs=[8, 9, 10], _stateful_parallelism=false, body=lstm_while_body_101[], cond=lstm_while_cond_100[], output_shapes=[[], [], [], [], [?,96], 17584562593488234240, [], [], [], [], []], parallel_iterations=32](lstm/while/loop_counter, lstm/while/maximum_iterations, lstm/time, lstm/TensorArrayV2_1, lstm/zeros, lstm/zeros_1, lstm/strided_slice_1, lstm/TensorArrayUnstack/TensorListFromTensor, lstm/lstm_cell/kernel, lstm/lstm_cell/recurrent_kernel, lstm/lstm_cell/bias, lstm/while/EmptyTensorList, lstm/while/EmptyTensorList_1, lstm/while/EmptyTensorList_2, lstm/while/EmptyTensorList_3, lstm/while/EmptyTensorList_4, lstm/while/EmptyTensorList_5, lstm/while/EmptyTensorList_6, lstm/while/EmptyTensorList_7, lstm/while/EmptyTensorList_8, lstm/while/EmptyTensorList_9, lstm/while/EmptyTensorList_10, lstm/while/EmptyTensorList_11, lstm/while/EmptyTensorList_12, lstm/while/EmptyTensorList_13, lstm/while/EmptyTensorList_14, lstm/while/EmptyTensorList_15, lstm/while/EmptyTensorList_16, lstm/while/EmptyTensorList_17, lstm/while/EmptyTensorList_18, lstm/while/EmptyTensorList_19, lstm/while/EmptyTensorList_20, lstm/while/EmptyTensorList_21, lstm/while/EmptyTensorList_22, lstm/while/EmptyTensorList_23, lstm/while/EmptyTensorList_24, lstm/while/EmptyTensorList_25, lstm/while/EmptyTensorList_26, lstm/while/EmptyTensorList_27, lstm/while/EmptyTensorList_28, lstm/while/EmptyTensorList_29, lstm/while/EmptyTensorList_30, lstm/while/EmptyTensorList_31, lstm/while/EmptyTensorList_32)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.
2022-12-08 20:13:45.419488: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
/home/ubuntu/anaconda3/envs/cs-230-project/lib/python3.9/site-packages/keras/engine/training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.
  updates = self.state_updates
3300/3300 - 473s - loss: 0.0374 - mean_squared_error: 0.0084 - root_mean_squared_error: 0.0917 - val_loss: 0.0295 - val_mean_squared_error: 0.0026 - val_root_mean_squared_error: 0.0507 - 473s/epoch - 143ms/step
Epoch 2/10
3300/3300 - 472s - loss: 0.0294 - mean_squared_error: 0.0016 - root_mean_squared_error: 0.0397 - val_loss: 0.0281 - val_mean_squared_error: 9.1436e-04 - val_root_mean_squared_error: 0.0302 - 472s/epoch - 143ms/step
Epoch 3/10
3300/3300 - 467s - loss: 0.0276 - mean_squared_error: 6.2455e-04 - root_mean_squared_error: 0.0250 - val_loss: 0.0277 - val_mean_squared_error: 4.1839e-04 - val_root_mean_squared_error: 0.0205 - 467s/epoch - 141ms/step
Epoch 4/10
3300/3300 - 467s - loss: 0.0275 - mean_squared_error: 9.4477e-04 - root_mean_squared_error: 0.0307 - val_loss: 0.0273 - val_mean_squared_error: 0.0017 - val_root_mean_squared_error: 0.0411 - 467s/epoch - 141ms/step
Epoch 5/10
3300/3300 - 470s - loss: 0.0244 - mean_squared_error: 0.0018 - root_mean_squared_error: 0.0421 - val_loss: 0.0259 - val_mean_squared_error: 0.0022 - val_root_mean_squared_error: 0.0474 - 470s/epoch - 142ms/step
Epoch 6/10
3300/3300 - 469s - loss: 0.0242 - mean_squared_error: 0.0024 - root_mean_squared_error: 0.0487 - val_loss: 0.0232 - val_mean_squared_error: 0.0024 - val_root_mean_squared_error: 0.0487 - 469s/epoch - 142ms/step
Epoch 7/10
3300/3300 - 464s - loss: 0.0238 - mean_squared_error: 0.0027 - root_mean_squared_error: 0.0524 - val_loss: 0.0230 - val_mean_squared_error: 0.0028 - val_root_mean_squared_error: 0.0527 - 464s/epoch - 141ms/step
Epoch 8/10
3300/3300 - 464s - loss: 0.0236 - mean_squared_error: 0.0030 - root_mean_squared_error: 0.0547 - val_loss: 0.0226 - val_mean_squared_error: 0.0029 - val_root_mean_squared_error: 0.0535 - 464s/epoch - 141ms/step
Epoch 9/10
3300/3300 - 431s - loss: 0.0224 - mean_squared_error: 0.0029 - root_mean_squared_error: 0.0542 - val_loss: 0.0231 - val_mean_squared_error: 0.0031 - val_root_mean_squared_error: 0.0558 - 431s/epoch - 131ms/step
Epoch 10/10
3300/3300 - 227s - loss: 0.0227 - mean_squared_error: 0.0031 - root_mean_squared_error: 0.0556 - val_loss: 0.0227 - val_mean_squared_error: 0.0032 - val_root_mean_squared_error: 0.0562 - 227s/epoch - 69ms/step
Traceback (most recent call last):
  File "/home/ubuntu/cs230-project/trainLSTM.py", line 303, in <module>
    plotLossOverEpochs(history.history,'training_'+loss_f+'_'+str(nHLayers)+'_'+str(nHUnits)+'_'+str(learning_r))
  File "/home/ubuntu/cs230-project/utilities.py", line 73, in plotLossOverEpochs
    plt.savefig(fig_name)
  File "/home/ubuntu/anaconda3/envs/cs-230-project/lib/python3.9/site-packages/matplotlib/pyplot.py", line 954, in savefig
    res = fig.savefig(*args, **kwargs)
  File "/home/ubuntu/anaconda3/envs/cs-230-project/lib/python3.9/site-packages/matplotlib/figure.py", line 3274, in savefig
    self.canvas.print_figure(fname, **kwargs)
  File "/home/ubuntu/anaconda3/envs/cs-230-project/lib/python3.9/site-packages/matplotlib/backend_bases.py", line 2285, in print_figure
    with cbook._setattr_cm(self, manager=None), \
  File "/home/ubuntu/anaconda3/envs/cs-230-project/lib/python3.9/contextlib.py", line 119, in __enter__
    return next(self.gen)
  File "/home/ubuntu/anaconda3/envs/cs-230-project/lib/python3.9/site-packages/matplotlib/backend_bases.py", line 2192, in _switch_canvas_and_return_print_method
    raise ValueError(
ValueError: Format '8006639526316317e-05' is not supported (supported formats: eps, jpeg, jpg, pdf, pgf, png, ps, raw, rgba, svg, svgz, tif, tiff, webp)
